{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook briefly walks through fitting the four linear Bayesian regression calibrations for global core top $\\delta^{18}\\mathrm{O}_{\\mathrm{c}}$ and SSTs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook settings for graphics and load some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pymc as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lgmproxies.datasets.tierney import get_repo_path\n",
    "prefix = get_repo_path(\"brews/d18oc_sst\").as_posix() + \"/notebooks/\"\n",
    "prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set paths to our core top data. These are also given as supplemental information in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coretop_path = prefix + '../data/parsed/coretops.csv'\n",
    "coretop_grid_path = prefix + '../data/parsed/coretops_grid.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read coretop data and parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coretops_raw = pd.read_csv(coretop_path)\n",
    "coretops_grid = pd.read_csv(coretop_grid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coretops_raw['foramtype'] = coretops_raw['species'].astype('category')\n",
    "coretops_grid['foramtype'] = coretops_grid['species'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a quick look at the data to see what we're dealing with... (and make sure everything is there)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coretops_raw['foramtype'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coretops_raw['foramtype'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coretops_grid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annual SST pooled model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model setup that pools all foram species together and calibrates on annual-mean SSTs.\n",
    "\n",
    "Models is:\n",
    "\\begin{align}\n",
    "\\delta^{18}O_c = \\alpha + \\beta * T + \\delta^{18}O_{sw} - 0.27 + \\epsilon \\\\\n",
    "\\end{align}\n",
    "\n",
    "with parameters:\n",
    "\\begin{align}\n",
    "\\alpha \\sim \\mathcal{N}(3, 4) \\\\\n",
    "\\beta \\sim \\mathcal{N}(-0.2, 1) \\\\\n",
    "\\epsilon \\sim \\mathcal{N}(0, \\tau) \\\\\n",
    "\\tau \\sim \\mathrm{HalfCauchy}(1)\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the original `coretops_grid` to `coretops`, which is our working copy. Then we make a `temp` column from the annual SST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coretops = coretops_grid.copy()\n",
    "coretops['temp'] = coretops['t_annual']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives you an idea what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coretops.shape)\n",
    "coretops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the number of gridpoints we have for each foram species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coretops.foramtype.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define the model and sample it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coretops['d18osw'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = coretops['temp'].values\n",
    "d18osw = coretops['d18osw'].values\n",
    "d18oc = coretops['d18oc'].values\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Intercept and slope\n",
    "    a = pm.Normal('a', mu=3.0, sigma=2)\n",
    "    b = pm.Normal('b', mu=-0.2, sigma=1)\n",
    "\n",
    "    # Model error\n",
    "    tau = pm.HalfCauchy('tau', beta=1)\n",
    "\n",
    "    # Likelihood\n",
    "    d18oc_est = a + b * temp + (d18osw - 0.27)\n",
    "    pm.Deterministic('d18oc_est', d18oc_est)\n",
    "    likelihood_d18oc = pm.Normal('likelihood_d18oc', mu=d18oc_est, sigma=tau,\n",
    "                                 observed=d18oc)\n",
    "    trace = pm.sample(draws=5000, tune=1000, chains=2, init='jitter+adapt_diag', random_seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very basic diagnostic plots showing the sampling and posterior distribution of the parameters. Remember that the trace plot (below) has two lines on each plot, one for each chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz\n",
    "arviz.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arviz.plot_forest(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace, hdi_prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our PSIS-LOO statistics, for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    pm.compute_log_likelihood(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.stats.loo(trace, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model and trace for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cloudpickle as cp\n",
    "resultsdir = Path(\"../modelresults/\")\n",
    "resultsdir.mkdir(parents=True, exist_ok=True)\n",
    "cp.dump(model, open(resultsdir/'deltao18_annual.cpkl', 'wb'))\n",
    "trace.to_netcdf(resultsdir/'deltao18_annual.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal SST pooled model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same deal as before. This is a model setup that pools all foram species together but calibrates against the seasonal SSTs instead of annual.\n",
    "\n",
    "Models is:\n",
    "\\begin{align}\n",
    "\\delta^{18}O_c = \\alpha + \\beta * T + \\delta^{18}O_{sw} - 0.27 + \\epsilon \\\\\n",
    "\\end{align}\n",
    "\n",
    "with parameters:\n",
    "\\begin{align}\n",
    "\\alpha \\sim \\mathcal{N}(3, 4) \\\\\n",
    "\\beta \\sim \\mathcal{N}(-0.2, 1) \\\\\n",
    "\\epsilon \\sim \\mathcal{N}(0, \\tau) \\\\\n",
    "\\tau \\sim \\mathrm{HalfCauchy}(1)\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coretops = coretops_grid.copy()\n",
    "coretops['temp'] = coretops['t_seasonal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coretops.shape)\n",
    "coretops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define the model and sample..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = coretops['temp'].values\n",
    "d18osw = coretops['d18osw'].values\n",
    "d18oc = coretops['d18oc'].values\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Intercept and slope\n",
    "    a = pm.Normal('a', mu=3.0, sd=2)\n",
    "    b = pm.Normal('b', mu=-0.2, sd=1)\n",
    "\n",
    "    # Model error\n",
    "    tau = pm.HalfCauchy('tau', beta=1)\n",
    "\n",
    "    # Likelihood\n",
    "    d18oc_est = a + b * temp + (d18osw - 0.27)\n",
    "    likelihood_d18oc = pm.Normal('likelihood_d18oc', mu=d18oc_est, sd=tau,\n",
    "                                 observed=d18oc)\n",
    "    trace = pm.sample(draws=5000, tune=1000, chains=2, init='jitter+adapt_diag', random_seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagnostic plots..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.traceplot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.forestplot(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSIS-LOO, the cross-validation statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.stats.loo(trace, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annual SST hierarchical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the hierarchical model setup, calibrated on annual SSTs. We're allowing some wiggle room in the parameters, for the individual species.\n",
    "\n",
    "Models is:\n",
    "\\begin{align}\n",
    "\\delta^{18}O_c = \\alpha_i + \\beta_i * T + \\delta^{18}O_{sw} - 0.27 + \\epsilon \\\\\n",
    "\\end{align}\n",
    "\n",
    "using parameters set for individual foram species ($i$):\n",
    "\\begin{align}\n",
    "\\epsilon \\sim \\mathcal{N}(0, \\tau_i) \\\\\n",
    "\\alpha_i \\sim \\mathcal{N}(\\mu_\\alpha, \\sigma_\\alpha) \\\\\n",
    "\\beta_i \\sim \\mathcal{N}(\\mu_\\beta, \\sigma_\\beta) \\\\\n",
    "\\tau_i \\sim \\mathrm{\\Gamma}( \\frac{\\sigma_m^2} {\\sigma_d^2}, \\frac{\\sigma_m} {\\sigma_d^2} ) \\\\\n",
    "\\end{align}\n",
    "\n",
    "and hyperparameters:\n",
    "\\begin{align}\n",
    "\\mu_\\alpha \\sim \\mathcal{N}(3, 4) \\\\\n",
    "\\mu_\\beta \\sim \\mathcal{N}(-0.2, 1) \\\\\n",
    "\\sigma_\\alpha \\sim \\mathrm{HalfCauchy}(0.5) \\\\\n",
    "\\sigma_\\beta \\sim \\mathrm{HalfCauchy}(0.25) \\\\\n",
    "\\sigma_m \\sim \\mathrm{HalfCauchy}(1) \\\\\n",
    "\\sigma_d \\sim \\mathrm{HalfCauchy}(1) \\\\\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest follows what we had before.\n",
    "\n",
    "Let's make a new copy of the core top data and set `temp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coretops = coretops_grid.copy()\n",
    "coretops['temp'] = coretops['t_annual']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model and sample from it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = coretops['temp'].values\n",
    "d18osw = coretops['d18osw'].values\n",
    "d18oc = coretops['d18oc'].values\n",
    "foramtype = coretops['foramtype'].cat.codes\n",
    "n_foram = len(set(foramtype))\n",
    "\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Hyperparameters\n",
    "    mu_a = pm.Normal('mu_a', mu=3, sigma=2)\n",
    "    sigma_a = pm.HalfCauchy('sigma_a', beta=0.5)\n",
    "\n",
    "    mu_b = pm.Normal('mu_b', mu=-0.2, sigma=1)\n",
    "    sigma_b = pm.HalfCauchy('sigma_b', beta=0.25)\n",
    "\n",
    "    sigma_m = pm.HalfCauchy('sigma_m', beta=1)\n",
    "    sigma_d = pm.HalfCauchy('sigma_d', beta=1)\n",
    "\n",
    "    # Intercept and slope\n",
    "    a = pm.Normal('a', mu=mu_a, sigma=sigma_a, shape=n_foram)\n",
    "    b = pm.Normal('b', mu=mu_b, sigma=sigma_b, shape=n_foram)\n",
    "\n",
    "    # Model error\n",
    "    tau = pm.Gamma('tau', alpha=sigma_m**2 / sigma_d**2,\n",
    "                          beta=sigma_m / sigma_d**2,\n",
    "                          shape=n_foram)\n",
    "\n",
    "    # Likelihood\n",
    "    d18oc_est = a[foramtype] + b[foramtype] * temp + (d18osw - 0.27)\n",
    "    pm.Deterministic('d18oc_est', d18oc_est)\n",
    "    likelihood_d18oc = pm.Normal('likelihood_d18oc', mu=d18oc_est,\n",
    "                                 sigma=tau[foramtype], observed=d18oc)\n",
    "    trace = pm.sample(draws=5000, tune=1000, chains=2, init='jitter+adapt_diag', random_seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cloudpickle as cp\n",
    "resultsdir = Path(\"../modelresults/\")\n",
    "resultsdir.mkdir(parents=True, exist_ok=True)\n",
    "cp.dump(model, open(resultsdir/'deltao18_hierarchical_annual.cpkl', 'wb'))\n",
    "trace.to_netcdf(resultsdir/'deltao18_hierarchical_annual.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lgmproxies.datasets.tierney import DeltaO18, DeloSWMalevitch, DeltaO18Hierarchical\n",
    "\n",
    "def convert_d18o_df_tierney(df, lgm=False, hierarchical=False):\n",
    "    deloswvals = delosw.interpolate(df[\"Longitude\"], df[\"Latitude\"])\n",
    "    if hierarchical:\n",
    "        return deltaO18Hierarchicalmodel.to_sst(df[\"ProxyValue\"].values, df[\"Species\"].values, deloswvals, seed=3422)\n",
    "    else:\n",
    "        return deltaO18model.to_sst(df[\"ProxyValue\"].values, deloswvals, seed=345)\n",
    "\n",
    "delosw = DeloSWMalevitch()\n",
    "deltaO18model = DeltaO18.load(\"../modelresults/deltao18_annual.cpkl\", \"../modelresults/deltao18_annual.nc\")\n",
    "deltaO18Hierarchicalmodel = DeltaO18Hierarchical.load(\"../modelresults/deltao18_hierarchical_annual.cpkl\", \"../modelresults/deltao18_hierarchical_annual.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = deltaO18Hierarchicalmodel.trace\n",
    "model = deltaO18Hierarchicalmodel.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = coretops['temp'].values\n",
    "d18osw = coretops['d18osw'].values\n",
    "d18oc = coretops['d18oc'].values\n",
    "foramtype = coretops['foramtype'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled = np.median(deltaO18model.to_sst(d18oc, d18osw, seed=123), axis=0)\n",
    "hierarchical = np.median(deltaO18Hierarchicalmodel.to_sst(d18oc, foramtype, d18osw, seed=123), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "r2pooled = np.corrcoef(pooled, temp)[0, 1]**2\n",
    "rms = np.sqrt(np.mean((pooled - temp)**2))\n",
    "r2h = np.corrcoef(hierarchical, temp)[0, 1]**2\n",
    "rmsh = np.sqrt(np.mean((hierarchical - temp)**2))\n",
    "ax.scatter(temp, pooled, label=f'Pooled\\n$r^2=${r2pooled:.2f}\\nrms={rms:.1f}C', s=3)\n",
    "ax.scatter(temp, hierarchical, label=f'Hierarchical\\n$r^2=${r2h:.2f}\\nrms={rmsh:.1f}C', s=3)\n",
    "ax.set_xlabel('Temperature (C)')\n",
    "ax.set_ylabel('Estimated SST (C)')\n",
    "ax.set_title('Pooled vs Hierarchical SST Estimates')\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "f.savefig('../images/d18o_sst_pooled_vs_hierarchical.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "f, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "pooled = az.extract(deltaO18model.trace.posterior['d18oc_est'])['d18oc_est'].median(dim=\"sample\").values\n",
    "hierarchical = az.extract(deltaO18Hierarchicalmodel.trace.posterior['d18oc_est'])['d18oc_est'].median(dim=\"sample\").values\n",
    "r2pooled = np.corrcoef(pooled, d18oc)[0, 1]**2\n",
    "rms = np.sqrt(np.mean((pooled - d18oc)**2))\n",
    "r2h = np.corrcoef(hierarchical, d18oc)[0, 1]**2\n",
    "rmsh = np.sqrt(np.mean((hierarchical - d18oc)**2))\n",
    "ax.scatter(d18oc, pooled, label=f'Pooled\\n$r^2=${r2pooled:.2f}\\nrms={rms:.2f}%$_o$', s=3)\n",
    "ax.scatter(d18oc, hierarchical, label=f'Hierarchical\\n$r^2=${r2h:.2f}\\nrms={rmsh:.2f}%$_o$', s=3)\n",
    "ax.set_xlabel('Observed d18O (per mil)')\n",
    "ax.set_ylabel('Estimated d18O (per mil)')\n",
    "ax.set_title('Pooled vs Hierarchical deltaO18 Estimates')\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "f.savefig('../images/d18o_pooled_vs_hierarchical.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagnostic plots and such... same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(coretops['foramtype'].cat.codes, coretops['foramtype'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "az.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and the PSIS-LOO cross-validation statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    pm.compute_log_likelihood(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.stats.loo(trace, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal SST hierarchical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the same hierarchical model setup, but calibrated on seasonal SSTs.\n",
    "\n",
    "Models is:\n",
    "\\begin{align}\n",
    "\\delta^{18}O_c = \\alpha_i + \\beta_i * T + \\delta^{18}O_{sw} - 0.27 + \\epsilon \\\\\n",
    "\\end{align}\n",
    "\n",
    "using parameters set for individual foram species ($i$):\n",
    "\\begin{align}\n",
    "\\epsilon \\sim \\mathcal{N}(0, \\tau_i) \\\\\n",
    "\\alpha_i \\sim \\mathcal{N}(\\mu_\\alpha, \\sigma_\\alpha) \\\\\n",
    "\\beta_i \\sim \\mathcal{N}(\\mu_\\beta, \\sigma_\\beta) \\\\\n",
    "\\tau_i \\sim \\mathrm{\\Gamma}( \\frac{\\sigma_m^2} {\\sigma_d^2}, \\frac{\\sigma_m} {\\sigma_d^2} ) \\\\\n",
    "\\end{align}\n",
    "\n",
    "and hyperparameters:\n",
    "\\begin{align}\n",
    "\\mu_\\alpha \\sim \\mathcal{N}(3, 4) \\\\\n",
    "\\mu_\\beta \\sim \\mathcal{N}(-0.2, 1) \\\\\n",
    "\\sigma_\\alpha \\sim \\mathrm{HalfCauchy}(0.5) \\\\\n",
    "\\sigma_\\beta \\sim \\mathrm{HalfCauchy}(0.25) \\\\\n",
    "\\sigma_m \\sim \\mathrm{HalfCauchy}(1) \\\\\n",
    "\\sigma_d \\sim \\mathrm{HalfCauchy}(1) \\\\\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coretops = coretops_grid.copy()\n",
    "coretops['temp'] = coretops['t_seasonal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and sample it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = coretops['temp'].values\n",
    "d18osw = coretops['d18osw'].values\n",
    "d18oc = coretops['d18oc'].values\n",
    "foramtype = coretops['foramtype'].cat.codes\n",
    "n_foram = len(set(foramtype))\n",
    "\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Hyperparameters\n",
    "    mu_a = pm.Normal('mu_a', mu=3, sd=2)\n",
    "    sigma_a = pm.HalfCauchy('sigma_a', beta=0.5)\n",
    "\n",
    "    mu_b = pm.Normal('mu_b', mu=-0.2, sd=1)\n",
    "    sigma_b = pm.HalfCauchy('sigma_b', beta=0.25)\n",
    "\n",
    "    sigma_m = pm.HalfCauchy('sigma_m', beta=1)\n",
    "    sigma_d = pm.HalfCauchy('sigma_d', beta=1)\n",
    "\n",
    "    # Intercept and slope\n",
    "    a = pm.Normal('a', mu=mu_a, sd=sigma_a, shape=n_foram)\n",
    "    b = pm.Normal('b', mu=mu_b, sd=sigma_b, shape=n_foram)\n",
    "\n",
    "    # Model error\n",
    "    tau = pm.Gamma('tau', alpha=sigma_m**2 / sigma_d**2,\n",
    "                          beta=sigma_m / sigma_d**2,\n",
    "                          shape=n_foram)\n",
    "\n",
    "    # Likelihood\n",
    "    d18oc_est = a[foramtype] + b[foramtype] * temp + (d18osw - 0.27)\n",
    "    likelihood_d18oc = pm.Normal('likelihood_d18oc', mu=d18oc_est,\n",
    "                                 sd=tau[foramtype], observed=d18oc)\n",
    "    trace = pm.sample(draws=5000, tune=1000, chains=2, init='jitter+adapt_diag', random_seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagnostics..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.traceplot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.forestplot(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our PSIS-LOO cross-validation statistic..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.stats.loo(trace, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
